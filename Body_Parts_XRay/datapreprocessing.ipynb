{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, val and test folders\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Read the CSV file and shuffle the rows\n",
    "df = pd.read_csv('/mnt/g/Datasets/Body_Parts_XRay/train_df.csv').sample(frac=1).reset_index(drop=True)\n",
    "# Create a new column of filename\n",
    "df['filename'] = df['image_path'].apply(lambda x: os.path.basename(x))\n",
    "# save the df\n",
    "df.to_csv('/mnt/g/Datasets/Body_Parts_XRay/train_df_new.csv', index=False)\n",
    "\n",
    "source_folder_path = '/mnt/g/Datasets/Body_Parts_XRay/images/train/'\n",
    "dest_folder_path = '/mnt/g/Datasets/Body_Parts_XRay/Original/'\n",
    "\n",
    "# Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define a function to copy files\n",
    "def copy_files(df, dest_folder):\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        src_file = os.path.join(source_folder_path, filename)\n",
    "        dest_file = os.path.join(dest_folder_path, dest_folder, 'images',filename)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Copy files to their respective folders\n",
    "copy_files(train_df, 'train')\n",
    "copy_files(val_df, 'val')\n",
    "copy_files(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200 201 202 ...  27  27  27]\n",
      " [199 200 201 ...  26  27  27]\n",
      " [203 202 202 ...  26  27  27]\n",
      " ...\n",
      " [ 27  27  27 ...  17   0   1]\n",
      " [ 26  27  27 ...  35   0   0]\n",
      " [ 27  27  26 ...  50   8   0]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/train/images/1.2.826.0.1.3680043.8.498.10038426859954986240523417641213777162-c.png'\n",
    "img = Image.open(source_folder)\n",
    "img = np.array(img)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 4 black regions at all 4 edges. Add black padding to make it square\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def remove_dark_edges(source_folder, destination_folder):\n",
    "    \"\"\"Remove dark edges from the image.\"\"\"\n",
    "\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    def remove_dark_edges(img):\n",
    "        \"\"\"Remove dark edges from the image.\"\"\"\n",
    "        data = img.load()\n",
    "        width, height = img.size\n",
    "        \n",
    "        left, right = 0, width\n",
    "        top, bottom = 0, height\n",
    "        \n",
    "        def is_dark(pixel):\n",
    "            if isinstance(pixel, int):\n",
    "                return pixel < 5\n",
    "            return pixel < (5, 5, 5)\n",
    "        \n",
    "        # Check left edge\n",
    "        for x in range(width):\n",
    "            if not is_dark(data[x, height // 2]):\n",
    "                left = x\n",
    "                break\n",
    "                \n",
    "        # Check right edge\n",
    "        for x in range(width - 1, -1, -1):\n",
    "            if not is_dark(data[x, height // 2]):\n",
    "                right = x + 1\n",
    "                break\n",
    "                \n",
    "        # Check top edge\n",
    "        for y in range(height):\n",
    "            if not is_dark(data[width // 2, y]):\n",
    "                top = y\n",
    "                break\n",
    "                \n",
    "        # Check bottom edge\n",
    "        for y in range(height - 1, -1, -1):\n",
    "            if not is_dark(data[width // 2, y]):\n",
    "                bottom = y + 1\n",
    "                break\n",
    "                \n",
    "        return img.crop((left, top, right, bottom))\n",
    "\n",
    "    def add_black_padding(img):\n",
    "        \"\"\"Add black padding to make the image square.\"\"\"\n",
    "        width, height = img.size\n",
    "        size = max(width, height)\n",
    "        \n",
    "        new_img = Image.new(\"RGB\", (size, size), color=(0, 0, 0))\n",
    "        new_img.paste(img, ((size - width) // 2, (size - height) // 2))\n",
    "        \n",
    "        return new_img\n",
    "\n",
    "    for image_file in os.listdir(source_folder):\n",
    "        if image_file.endswith('.png'):\n",
    "            img_path = os.path.join(source_folder, image_file)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            img = remove_dark_edges(img)\n",
    "            if img.width != img.height:\n",
    "                img = add_black_padding(img)\n",
    "                \n",
    "            img.save(os.path.join(destination_folder, image_file))\n",
    "\n",
    "\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/train/images'\n",
    "destination_folder = '/mnt/g/Datasets/Body_Parts_XRay/Square/train/images'\n",
    "remove_dark_edges(source_folder, destination_folder)\n",
    "\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/val/images'\n",
    "destination_folder = '/mnt/g/Datasets/Body_Parts_XRay/Square/val/images'\n",
    "remove_dark_edges(source_folder, destination_folder)\n",
    "\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/test/images'\n",
    "destination_folder = '/mnt/g/Datasets/Body_Parts_XRay/Square/test/images'\n",
    "remove_dark_edges(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/test/images/'\n",
    "image_files = [f for f in os.listdir(source_folder) if f.endswith('.png')]\n",
    "print(image_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mlfoundations/open_clip/issues/439\n",
    "\n",
    "#Code to implement data augmentation: --aug-cfg scale='(0.33, 1.0)' re_prob=0.35\n",
    "\"\"\"\n",
    "A.Affine(rotate=(-15, 15), translate_percent=(0.0, 0.25), shear=(-3, 3), p=0.5),\n",
    "A.RandomResizedCrop(image_size[0], image_size[1], scale=(0.9, 1.0), ratio=(0.75, 1.3333333333)),\n",
    "A.ToGray(p=0.1),\n",
    "A.GaussianBlur(blur_limit=(3, 7), p=0.05),\n",
    "A.GaussNoise(p=0.05),\n",
    "A.RandomGridShuffle(grid=(2, 2), p=0.3),\n",
    "A.Posterize(p=0.2),\n",
    "A.RandomBrightnessContrast(p=0.5),\n",
    "A.Cutout(p=0.05),\n",
    "A.RandomSnow(p=0.1),\n",
    "A.RandomRain(p=0.05),\n",
    "A.HorizontalFlip(p=0.5),\n",
    "\"\"\"\n",
    "\n",
    "from torchvision.transforms import Normalize, Compose, RandomResizedCrop, InterpolationMode, ToTensor, Resize, CenterCrop\n",
    "\n",
    "def _convert_to_rgb(image):\n",
    "    return image.convert('RGB')\n",
    "normalize = Normalize(mean=mean, std=std)\n",
    "train_transform = Compose([\n",
    "    RandomResizedCrop(\n",
    "        image_size,\n",
    "        scale=aug_cfg_dict.pop('scale'),\n",
    "        interpolation=InterpolationMode.BICUBIC,\n",
    "    ),\n",
    "    _convert_to_rgb,\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (Normalize, Compose, RandomResizedCrop, RandomRotation, \n",
    "                                   RandomHorizontalFlip, ColorJitter, RandomAffine, \n",
    "                                   GaussianBlur, RandomCrop, RandomErasing, InterpolationMode, \n",
    "                                   ToTensor, Resize, CenterCrop)\n",
    "\n",
    "def _convert_to_rgb(image):\n",
    "    return image.convert('RGB')\n",
    "\n",
    "normalize = Normalize(mean=mean, std=std)\n",
    "\n",
    "train_transform = Compose([\n",
    "    RandomRotation(degrees=15),  # Small rotations\n",
    "    RandomResizedCrop(           # Scaling and Zooming\n",
    "        image_size,\n",
    "        scale=aug_cfg_dict.pop('scale'),\n",
    "        interpolation=InterpolationMode.BICUBIC,\n",
    "    ),\n",
    "    RandomHorizontalFlip(p=0.5),  # Horizontal Flip\n",
    "    ColorJitter(brightness=0.2, contrast=0.2),  # Brightness and Contrast Adjustments\n",
    "    # Note: torchvision doesn't have a direct function for translation. \n",
    "    # But, RandomAffine with 'translate' can achieve this.\n",
    "    RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translation (10% of total image size)\n",
    "    # Note: torchvision doesn't have elastic deformation or histogram equalization.\n",
    "    RandomCrop(size=image_size, padding=10),  # Cropping\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Gaussian Blur\n",
    "    RandomErasing(p=0.1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # Cutout or Random Erasing\n",
    "    _convert_to_rgb,\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\"\"\"\n",
    "This transform chain integrates the suggested augmentations. Some points to consider:\n",
    "\n",
    "Ensure that the order of transformations is appropriate. For example, always apply ToTensor() before Normalize().\n",
    "For augmentations not available in torchvision, you might want to integrate the albumentations library, which offers a rich set of image transformations.\n",
    "Always consult with domain experts (in this case, radiologists or medical imaging experts) to ensure that the chosen augmentations do not introduce artifacts that could mislead the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.to_tensor(img).numpy() * 255  # Convert to numpy array in range [0, 255]\n",
    "        img = img.transpose(1, 2, 0)  # Convert from CxHxW to HxWxC\n",
    "        img = self.transform(image=img)['image']\n",
    "        img = F.to_pil_image(img.astype('uint8'))  # Convert back to PIL image\n",
    "        return img\n",
    "\n",
    "# Albumentations transformations\n",
    "albu_transforms = A.Compose([\n",
    "    A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),  # Elastic deformation\n",
    "    A.HistogramMatching(p=0.5, reference_images=None),  # Histogram Equalization (note: you need reference images)\n",
    "    # Add any other albumentations transforms here\n",
    "])\n",
    "\n",
    "# torchvision transforms\n",
    "pre_transforms = Compose([\n",
    "    _convert_to_rgb,\n",
    "    RandomRotation(degrees=15),\n",
    "    RandomResizedCrop(\n",
    "        image_size,\n",
    "        scale=aug_cfg_dict.pop('scale'),\n",
    "        interpolation=InterpolationMode.BICUBIC,\n",
    "    ),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    RandomCrop(size=image_size, padding=10),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "post_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "    RandomErasing(p=0.1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # Cutout or Random Erasing\n",
    "])\n",
    "\n",
    "train_transform = Compose([\n",
    "    pre_transforms,\n",
    "    AlbumentationsTransform(albu_transforms),\n",
    "    post_transforms\n",
    "])\n",
    "\"\"\"\n",
    "The AlbumentationsTransform class acts as a bridge between torchvision and albumentations.\n",
    "The HistogramMatching transformation in albumentations requires a set of reference images to match the histogram. You'd need to specify that.\n",
    "Always ensure that ToTensor() is one of the last transformations, because it changes the data type and order of dimensions.\n",
    "Test the transformation pipeline on a few images to ensure it's working as expected.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To visualize the augmentation on a few images, you can follow the steps below:\n",
    "\n",
    "Load a few images.\n",
    "Apply the transformation pipeline train_transform to each image.\n",
    "Display the original and augmented images side by side using matplotlib.\n",
    "\n",
    "Remember to change path_to_your_images to the directory where your images are located. \n",
    "The code will display the original and augmented images side by side for the first five images in the directory. \n",
    "This will allow you to inspect the effects of your augmentation pipeline.\n",
    "\"\"\"\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_augmentations(original_img, augmented_img):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(original_img)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(augmented_img)\n",
    "    ax[1].set_title(\"Augmented Image\")\n",
    "    for a in ax:\n",
    "        a.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Load a few images\n",
    "image_folder = \"path_to_your_images\"  # Change this to your image directory\n",
    "sample_images = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder)[:5]]\n",
    "\n",
    "for image_path in sample_images:\n",
    "    original_img = Image.open(image_path)\n",
    "    augmented_img = train_transform(original_img)\n",
    "    augmented_img = augmented_img.permute(1, 2, 0)  # Convert CxHxW to HxWxC for visualization\n",
    "    visualize_augmentations(original_img, augmented_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate captions.txt for image folder\n",
    "\n",
    "import os\n",
    "# Dictionary to map integers to tissue types\n",
    "tissue_map = {\n",
    "    0: \"Abdomen\",\n",
    "    1: \"Ankle\",\n",
    "    2: \"Cervical Spine\",\n",
    "    3: \"Chest\",\n",
    "    4: \"Clavicles\",\n",
    "    5: \"Elbow\",\n",
    "    6: \"Feet\",\n",
    "    7: \"Finger\",\n",
    "    8: \"Forearm\",\n",
    "    9: \"Hand\",\n",
    "    10: \"Hip\",\n",
    "    11: \"Knee\",\n",
    "    12: \"Lower Leg\",\n",
    "    13: \"Lumbar Spine\",\n",
    "    14: \"Others\",\n",
    "    15: \"Pelvis\",\n",
    "    16: \"Shoulder\",\n",
    "    17: \"Sinus\",\n",
    "    18: \"Skull\",\n",
    "    19: \"Thigh\",\n",
    "    20: \"Thoracic Spine\",\n",
    "    21: \"Wrist\"\n",
    "}\n",
    "\n",
    "def generate_caption (source_folder, output_file):\n",
    "    # List all jpg images in the source folder\n",
    "    image_files = [f for f in os.listdir(source_folder) if f.endswith('.png')]\n",
    "\n",
    "    # Extract the base name of the image files\n",
    "    df = pd.read_csv('/mnt/g/Datasets/Body_Parts_XRay/train_df_new.csv')\n",
    "\n",
    "    # Create a new column 'tissue_types' to store the tissue types in a readable format\n",
    "    def map_to_tissue(target):\n",
    "        tissue_types = [tissue_map[int(t)] for t in target.split()]\n",
    "        return \", \".join(tissue_types)\n",
    "    df['tissue_types'] = df['Target'].apply(map_to_tissue)\n",
    "    # Optionally, save the updated dataframe to a new CSV\n",
    "    df.to_csv('/mnt/g/Datasets/Body_Parts_XRay/train_df_new1.csv', index=False)\n",
    "\n",
    "    # Open the output txt file for writing\n",
    "    with open(output_file, 'w') as f:\n",
    "        for filename in image_files:\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            #Look up the tissue types based on the filename\n",
    "            image_tissue_types = df[df['filename'] == filename]['tissue_types'].values[0]\n",
    "            # Write to the txt file\n",
    "            f.write(f\"{base_name}\\t{image_tissue_types}\\n\")\n",
    "\n",
    "\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/test/images/'\n",
    "output_file = '/mnt/g/Datasets/Body_Parts_XRay/Original/test/captions.txt'\n",
    "generate_caption (source_folder, output_file)\n",
    "\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/val/images/'\n",
    "output_file = '/mnt/g/Datasets/Body_Parts_XRay/Original/val/captions.txt'\n",
    "generate_caption (source_folder, output_file)\n",
    "\n",
    "source_folder = '/mnt/g/Datasets/Body_Parts_XRay/Original/train/images/'\n",
    "output_file = '/mnt/g/Datasets/Body_Parts_XRay/Original/train/captions.txt'\n",
    "generate_caption (source_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python generate_roco_csv.py --dataset_dir \"/mnt/e/Temp_data/Body_Parts_XRay/Original/train\" --input_text_name \"captions.txt\" --out_dir \"../Body_Parts_XRay/\" --out_csv_file \"train.csv\"\n",
    "# python generate_roco_csv.py --dataset_dir \"/mnt/e/Temp_data/Body_Parts_XRay/Original/val/\" --input_text_name \"captions.txt\" --out_dir \"../Body_Parts_XRay/\" --out_csv_file \"val.csv\"\n",
    "# python generate_roco_csv.py --dataset_dir \"/mnt/e/Temp_data/Body_Parts_XRay/Original/test\" --input_text_name \"captions.txt\" --out_dir \"../Body_Parts_XRay/\" --out_csv_file \"test.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
